{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res = (420, 236), n_data = 99120\n",
      "train_data.shape = torch.Size([99120, 1])\n",
      "uv.shape = torch.Size([99120, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x236 at 0x1EF681649D0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "data_img = Image.open(\"./test_small.png\")\n",
    "res = data_img.size\n",
    "n_data = res[0] * res[1]\n",
    "print(f\"res = {res}, n_data = {n_data}\")\n",
    "\n",
    "data_img_tensor = transforms.ToTensor()(data_img)[0]\n",
    "train_data = torch.reshape(\n",
    "        data_img_tensor,\n",
    "        (n_data, 1))\n",
    "\n",
    "print(f\"train_data.shape = {train_data.shape}\")\n",
    "\n",
    "# uv = np.mgrid[0:res[0]:1, 0:res[1]:1].reshape(2,-1).T\n",
    "# uv = torch.Tensor(uv).to(torch.long)\n",
    "# print(uv.shape)\n",
    "\n",
    "uv = torch.reshape(\n",
    "    torch.Tensor(np.array(range(0, res[0]*res[1]))),\n",
    "    (n_data, 1))\n",
    "\n",
    "print(f\"uv.shape = {uv.shape}\")\n",
    "\n",
    "transforms.ToPILImage()(data_img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Data Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "class customDataSet(Dataset):\n",
    "    def __init__(self, uv, data):\n",
    "        self.uv = uv \n",
    "        self.data = data\n",
    "        assert(self.data.shape[0] == n_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input = self.uv[idx]\n",
    "        label = self.data[idx]\n",
    "        return input, label\n",
    "\n",
    "train_dataset = customDataSet(uv, train_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "[1,   150] loss: 2370257.787\n",
      "[1,   300] loss: 2.263\n",
      "[1,   450] loss: 1.274\n",
      "[1,   600] loss: 1.290\n",
      "[1,   750] loss: 1.288\n",
      "Accuracy of the network on the 99120 test data pair:0.000000\n",
      "[2,   150] loss: 1.287\n",
      "[2,   300] loss: 1.303\n",
      "[2,   450] loss: 1.279\n",
      "[2,   600] loss: 1.297\n",
      "[2,   750] loss: 1.258\n",
      "Accuracy of the network on the 99120 test data pair:0.000000\n",
      "[3,   150] loss: 1.306\n",
      "[3,   300] loss: 1.259\n",
      "[3,   450] loss: 1.299\n",
      "[3,   600] loss: 1.279\n",
      "[3,   750] loss: 1.287\n",
      "Accuracy of the network on the 99120 test data pair:0.000000\n",
      "[4,   150] loss: 1.277\n",
      "[4,   300] loss: 1.296\n",
      "[4,   450] loss: 1.294\n",
      "[4,   600] loss: 1.269\n",
      "[4,   750] loss: 1.271\n",
      "Accuracy of the network on the 99120 test data pair:0.000000\n",
      "[5,   150] loss: 1.266\n",
      "[5,   300] loss: 1.272\n",
      "[5,   450] loss: 1.267\n",
      "[5,   600] loss: 1.307\n",
      "[5,   750] loss: 1.280\n",
      "Accuracy of the network on the 99120 test data pair:0.000000\n",
      "[6,   150] loss: 1.290\n",
      "[6,   300] loss: 1.303\n",
      "[6,   450] loss: 1.238\n",
      "[6,   600] loss: 1.275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_49300/3447117576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "\n",
    "class sdf_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sdf_net, self).__init__()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(1, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x \n",
    "\n",
    "model = sdf_net().to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def train(input, labels, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(input)\n",
    "    loss = loss_fn(pred, labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1) # the class with the highest energy is what we choose as prediction\n",
    "            total += labels.size(0)\n",
    "            correct += ( abs(predicted - labels) < 0.1 ).sum().item()\n",
    "\n",
    "    acc = (100 * correct / total)\n",
    "    print(f'Accuracy of the network on the {total} test data pair:{acc:2f}'  )\n",
    "    return acc \n",
    "\n",
    "\n",
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # print(i)\n",
    "\n",
    "        inputs, labels = data # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        inputs = inputs.float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        loss = train(inputs, labels, model, loss_fn, optimizer)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        n = 150\n",
    "        if i % n == n-1:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                (e + 1, i + 1, running_loss / n))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    acc = validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[61736]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0786],\n",
      "        [1.0829],\n",
      "        [1.0519],\n",
      "        ...,\n",
      "        [1.0285],\n",
      "        [1.0285],\n",
      "        [1.0285]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(44.8920)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = model(uv.to(device)).cpu().detach()\n",
    "print(fit)\n",
    "\n",
    "(fit - train_data.cpu().detach()).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAADsCAAAAAAeW41cAAADXklEQVR4nO3ZwW3bUBREUSlwB+m/ppQj7ZxFkIVhOI5sinz385wKCA8w8758/Xm93+63++12f70w0/XX0V9wuR79AeO9+BPN9+PoD+BzQgp4OfoDBhnb/DYpQN0FCCnAJo3zfoBsUoC6CxBSgJACDjocLOEjHA4B6i5ASAEnf8w2yt4mBai7ACEFnHyTZvhscmxSgLoLEFKAkAJ2Pxxs4OMcDgHqLkBIAad7zBbr3SYFqLsAIQWcbpOmeGRmbFKAugsQUoCQAp52ONi67TgcAtRdgJACTvOYLde6TQpQdwFCCjjNJk3jB9bFqLsAIQUIKeAph4Od25bDIUDdBQgpYMnH7GoVbpMC1F2AkAKW3KRpvjspNilA3QUIKUBIAZsfDjZuew6HAHUXIKSA5R6zK9a3TQpQdwFCClhuk6bZYk5sUoC6CxBSgJACvnQ42LF9ORwC1F2AkAKWeMyuXtk2KUDdBQgpYIlNmmbrCbFJAeouQEgBQgr49uFg057P4RCg7gKEFJB7zJ6xnm1SgLoLEFJAbpOm2WMubFKAugsQUoCQAh46HOzXMRwOAeouQEgBox+zqvgPmxSg7gKEFDB6k2qeNR02KUDdBQgpQEgBHx4OtmoOh0OAugsQUkDmMXvmWrZJAeouQEgBmU2aZs+ZsEkB6i5ASAFCCni5XM79UCxwOASouwAhBYx8zKrgt2xSgLoLEFLAyE3a2/TKt0kB6i5ASAFCCnh3ONioeRwOAeouQEgB4x+z6tgmJai7ACEFjN+kvU2sf5sUoO4ChBQgpIA3h4N9msnhEKDuAoQUcOhjVtX+H5sUoO4ChBTgB9YHHDUNNilA3QUIKcAmDfZ3imxSgLoLEFKAkAJ2Oxxs39c5HALUXYCQApZ9zK5U4zYpQN0FCClg2U2q+dfs2KQAdRcgpAAhBYw8HOzkWw6HAHUXIKSAkZu0t+mVb5MC1F2AkAJs0gEenRibFKDuAoQUIKSAbx8ONu35HA4B6i5ASAGne8wW6/36evQX8Cl1FyCkgNNt0t6KGwgAH9l114zo11z94ebzTgoQUsDSj9lVqtw//QLUXYCQApbepL09azpsUoC6CxBSgJACnnY42LrtOBwC1F2AkAKWecyuXNs2KUDdBQgpYJlNqnlkZmxSwG/YHQ2nr1SEkwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x236 at 0x1EF68151CA0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = torch.reshape(\n",
    "    fit,\n",
    "    (res[1], res[0])\n",
    ")\n",
    "\n",
    "fit_to_pil_img = transforms.ToPILImage()(fit)\n",
    "fit_to_pil_img"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f19e5527ea3a7295cf6de3374f84590014fff477197d10623aa6210afbfacf1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
